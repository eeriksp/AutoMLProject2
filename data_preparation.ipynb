{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3mu5qXvxg-zQ"
      },
      "source": [
        "## IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "BCQq1Hx2UOfT",
        "outputId": "58c6c33d-019a-48e5-c79a-050793e76ee7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.0)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.5.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.7)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.1.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (23.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.2.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2023.11.17)\n",
            "Requirement already satisfied: soundfile in /usr/local/lib/python3.10/dist-packages (0.12.1)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile) (2.21)\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-q394h_8l\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-q394h_8l\n",
            "  Resolved https://github.com/openai/whisper.git to commit 8bc8860694949db53c42ba47ddc23786c2e02a8b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.5.2)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "# downloading data\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "# saving data\n",
        "import csv\n",
        "\n",
        "# some basics\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "# for sound processing\n",
        "!pip install librosa\n",
        "import librosa\n",
        "import librosa.display\n",
        "!pip install soundfile\n",
        "import soundfile as sf\n",
        "from IPython.display import Audio\n",
        "\n",
        "# whisper\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "import whisper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5ebywr1hCWq"
      },
      "source": [
        "## DOWNLOADING DATA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pbq4gSGkWKKt",
        "outputId": "d00a843d-ff9d-4f91-d173-00535a4bf9a6"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-3b8a479202a4>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    127\u001b[0m   )\n\u001b[1;32m    128\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    130\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNbEsRnGhHdt"
      },
      "source": [
        "### ANDROID"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GaWkXs4VVZy"
      },
      "source": [
        "ANDROID DATASET (preprocessed, from google drive):\n",
        "\n",
        "reading_hc + interview_hc -> health control, non-depresed\n",
        "\n",
        "reading_pt + interview_pt -> patients, depressed\n",
        "\n",
        "all files have the same length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAz6pxaHVykW"
      },
      "outputs": [],
      "source": [
        "!gdown 'https://drive.google.com/uc?id=1OQ87c6vEKkTuLu2Z3jYz0P6-pvCytojz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYHeDVEWW5ia"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('/content/android_segmented_5s.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/android_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7wT8T0zOC003"
      },
      "outputs": [],
      "source": [
        "# paths to folders with data (the folder structure is not 100% straightforward, so maybe will be useful)\n",
        "android_interview_depressed_path = '/content/android_dataset/interview_pt/kaggle/working/segmented_files/interview_pt/'\n",
        "android_reading_depressed_path = '/content/android_dataset/reading_pt/'\n",
        "android_interview_healthy_path = '/content/android_dataset/interview_hc/'\n",
        "android_reading_healthy_path = '/content/android_dataset/reading_hc/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3cA-G_1C3-E"
      },
      "outputs": [],
      "source": [
        "android_interview_depressed_count = sum(1 for item in os.listdir(android_interview_depressed_path) if os.path.isfile(os.path.join(android_interview_depressed_path, item)))\n",
        "android_reading_depressed_count = sum(1 for item in os.listdir(android_reading_depressed_path) if os.path.isfile(os.path.join(android_reading_depressed_path, item)))\n",
        "android_interview_healthy_count = sum(1 for item in os.listdir(android_interview_healthy_path) if os.path.isfile(os.path.join(android_interview_healthy_path, item)))\n",
        "android_reading_healthy_count = sum(1 for item in os.listdir(android_reading_healthy_path) if os.path.isfile(os.path.join(android_reading_healthy_path, item)))\n",
        "\n",
        "print('android_interview_depressed_count: ', android_interview_depressed_count)\n",
        "print('android_reading_depressed_count: ', android_reading_depressed_count)\n",
        "print('android_interview_healthy_count: ', android_interview_healthy_count)\n",
        "print('android_reading_healthy_count: ', android_reading_healthy_count)\n",
        "\n",
        "android_count = android_interview_depressed_count + android_reading_depressed_count + android_interview_healthy_count + android_reading_healthy_count\n",
        "\n",
        "print('all samples: ', android_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G2pRWcOCWEUg"
      },
      "outputs": [],
      "source": [
        "# random sample, just to check what's going on\n",
        "audio_path = '/content/android_dataset/interview_pt/kaggle/working/segmented_files/interview_pt/01_PM58_2_0'\n",
        "data, sr = sf.read(audio_path, channels=2, samplerate=44100, format='RAW', subtype='PCM_16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O0e2m6yxe7Gb"
      },
      "outputs": [],
      "source": [
        "# if stereo convert to mono\n",
        "if data.shape[1] == 2:\n",
        "    data = librosa.to_mono(data.T)\n",
        "\n",
        "duration = librosa.get_duration(y=data, sr=sr)\n",
        "print(\"duration of file: \", duration)\n",
        "\n",
        "# I've testes the duration of a few random files, and it is always the same"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWZnDApGgb1J"
      },
      "outputs": [],
      "source": [
        "# check if recording is not silence (also done on a few random samples)\n",
        "frame_gains = np.abs(librosa.effects.preemphasis(data))\n",
        "silence_removed = any(frame_gains > 0)\n",
        "\n",
        "print(silence_removed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wCXgMRNhSa9"
      },
      "source": [
        "## E_DAIC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnDsVISoiAW4"
      },
      "source": [
        "E_DAIC DATASET (preprocessed, from drive)\n",
        "\n",
        "already splitted into train, test, validation sets\n",
        "\n",
        "labels in csv (https://drive.google.com/drive/folders/17jjD-cIZXS5EnqpvUNdosh6LCwDPYstX)\n",
        "\n",
        "labels meaning:  0 is non-depressed, 1 is depressed\n",
        "\n",
        "all files have the same length (also the same as the Android ones)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ulxJw_srhVPc"
      },
      "outputs": [],
      "source": [
        "!gdown 'https://drive.google.com/uc?id=1PT9Iij7DJOB1s4i0T4gT3jZxpoZqSpzU'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y6xgy179ixo5"
      },
      "outputs": [],
      "source": [
        "with zipfile.ZipFile('/content/edaic_segmented_5second.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/edaic_dataset')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zIUhysVWDNmW"
      },
      "outputs": [],
      "source": [
        "# paths to folders with data\n",
        "edaic_train_path = '/content/edaic_dataset/edaic_segmented_5second/segmented_files/train'\n",
        "edaic_test_path = '/content/edaic_dataset/edaic_segmented_5second/segmented_files/test'\n",
        "edaic_validation_path = '/content/edaic_dataset/edaic_segmented_5second/segmented_files/val'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8df2X5FBDj_I"
      },
      "outputs": [],
      "source": [
        "edaic_train_count = sum(1 for item in os.listdir(edaic_train_path) if os.path.isfile(os.path.join(edaic_train_path, item)))\n",
        "edaic_test_count = sum(1 for item in os.listdir(edaic_test_path) if os.path.isfile(os.path.join(edaic_test_path, item)))\n",
        "edaic_validation_count = sum(1 for item in os.listdir(edaic_validation_path) if os.path.isfile(os.path.join(edaic_validation_path, item)))\n",
        "\n",
        "print('edaic_train_count: ', edaic_train_count)\n",
        "print('edaic_test_count: ', edaic_test_count)\n",
        "print('edaic_validation_count: ', edaic_validation_count)\n",
        "\n",
        "edaic_count = edaic_train_count + edaic_test_count+ edaic_validation_count\n",
        "\n",
        "print('all samples: ', edaic_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "96OyMI8SDQLC"
      },
      "outputs": [],
      "source": [
        "# downloading labels\n",
        "\n",
        "# validation\n",
        "!gdown 'https://drive.google.com/uc?id=13PDjse2cjgT9Ns4s7v21DRbHB4nA2EtC'\n",
        "\n",
        "# training\n",
        "!gdown 'https://drive.google.com/uc?id=1LAEwPM3XPcDV3dh2XaxJKyKNdilBGVNK'\n",
        "\n",
        "# test\n",
        "!gdown 'https://drive.google.com/uc?id=1UQywlWldvqriiYDvNcj2iSq-fwvpIjA6'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEfIrBR9DScv"
      },
      "outputs": [],
      "source": [
        "edaic_train_labels = pd.read_csv('/content/edaic_training_labels.csv')\n",
        "edaic_test_labels = pd.read_csv('/content/edaic_testing_labels.csv')\n",
        "edaic_validation_labels = pd.read_csv('/content/edaic_validation_labels.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCN79yGpGSln"
      },
      "outputs": [],
      "source": [
        "edaic_train_labels.head(25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8f44w5ODYsp"
      },
      "outputs": [],
      "source": [
        "# numbers of samples in each set\n",
        "print(\"train: \", len(edaic_train_labels), \" test: \", len(edaic_test_labels), \" validation: \", len(edaic_validation_labels))\n",
        "print(\"all labels: \", len(edaic_train_labels) + len(edaic_test_labels) + len(edaic_validation_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cqy8tWUEwFS"
      },
      "source": [
        "The total number of labels differs from the number of all samples because there are multiple recordings of each individual (each person's recording is divided into many parts, with each part being identified by the individual's ID in the labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmEwIFTDFB4W"
      },
      "outputs": [],
      "source": [
        "# labeling each recording\n",
        "\n",
        "# train set\n",
        "edaic_train_labels_dict = edaic_train_labels.set_index('ID')['Value'].to_dict()\n",
        "edaic_train_recordings_names = os.listdir(edaic_train_path)\n",
        "edaic_train_recordings_labels = []\n",
        "for file in edaic_train_recordings_names:\n",
        "    file_id = file.split('_')[0]\n",
        "    if int(file_id) in edaic_train_labels_dict:\n",
        "        edaic_train_recordings_labels.append((file, edaic_train_labels_dict[int(file_id)]))\n",
        "    else:\n",
        "        edaic_train_recordings_labels.append((file, None))\n",
        "\n",
        "# test set\n",
        "edaic_test_labels_dict = edaic_test_labels.set_index('ID')['Value'].to_dict()\n",
        "edaic_test_recordings_names = os.listdir(edaic_test_path)\n",
        "edaic_test_recordings_labels = []\n",
        "for file in edaic_test_recordings_names:\n",
        "    file_id = file.split('_')[0]\n",
        "    if int(file_id) in edaic_test_labels_dict:\n",
        "        edaic_test_recordings_labels.append((file, edaic_test_labels_dict[int(file_id)]))\n",
        "    else:\n",
        "        edaic_test_recordings_labels.append((file, None))\n",
        "\n",
        "# validation set\n",
        "edaic_validation_labels_dict = edaic_validation_labels.set_index('ID')['Value'].to_dict()\n",
        "edaic_validation_recordings_names = os.listdir(edaic_validation_path)\n",
        "edaic_validation_recordings_labels = []\n",
        "\n",
        "for file in edaic_validation_recordings_names:\n",
        "    file_id = file.split('_')[0]\n",
        "    if int(file_id) in edaic_validation_labels_dict:\n",
        "        edaic_validation_recordings_labels.append((file, edaic_validation_labels_dict[int(file_id)]))\n",
        "    else:\n",
        "        edaic_validation_recordings_labels.append((file, None))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0-rCNw9jEEw"
      },
      "outputs": [],
      "source": [
        "audio_path = '/content/edaic_dataset/edaic_segmented_5second/segmented_files/test/600_AUDIO_0'\n",
        "data, sr = sf.read(audio_path, channels=2, samplerate=44100, format='RAW', subtype='PCM_16')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5SOmLDSpjgpD"
      },
      "outputs": [],
      "source": [
        "# if stereo convert to mono\n",
        "if data.shape[1] == 2:\n",
        "    data = librosa.to_mono(data.T)\n",
        "\n",
        "duration = librosa.get_duration(y=data, sr=sr)\n",
        "print(\"duration of file: \", duration)\n",
        "\n",
        "# I've testes the duration of a few random files, and it is always the same (also the same as for the android dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BkfhVa4PjiOX"
      },
      "outputs": [],
      "source": [
        "# check if recording is not silence\n",
        "frame_gains = np.abs(librosa.effects.preemphasis(data))\n",
        "silence_removed = any(frame_gains > 0)\n",
        "\n",
        "print(silence_removed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EbcU75-nU1i6"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import torch\n",
        "import librosa.display\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "# to play the audio files\n",
        "from IPython.display import Audio\n",
        "plt.style.use('seaborn-white')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RTA8x6y5SUFp"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jBos_5-HV8Cp"
      },
      "outputs": [],
      "source": [
        "# Whisper- Base\n",
        "from transformers import AutoFeatureExtractor, WhisperModel\n",
        "# from datasets import load_dataset\n",
        "\n",
        "model = WhisperModel.from_pretrained(\"openai/whisper-base\")\n",
        "feature_extractor = AutoFeatureExtractor.from_pretrained(\"openai/whisper-base\")\n",
        "model.to(device)\n",
        "import torchaudio\n",
        "def extract_features(path):\n",
        "    sample_rate = 16000\n",
        "    array, fs = torchaudio.load(path)\n",
        "    input = feature_extractor(array.squeeze(), sampling_rate = sample_rate, return_tensors = 'pt')\n",
        "    input = input.to(device)\n",
        "    input = input.input_features\n",
        "    with torch.no_grad():\n",
        "        outputs = model.encoder(input)\n",
        "    last_hidden_states = outputs.last_hidden_state.squeeze().mean(axis = 0).to(\"cpu\").numpy()\n",
        "    return last_hidden_states"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_xMu01O9Z5D"
      },
      "source": [
        "## Features extraction - WHISPER\n",
        "\n",
        "Extracting features from files, data saved as an array. 1st \"column\" is a file's name, second target value (0 - healthy, 1 - depressed), the rest are extracted features. Datasets are saved as csv files:\n",
        "\n",
        "- android_reading_healthy_whisper.csv\n",
        "- android_reading_depressed_whisper.csv\n",
        "- android_interview_healthy_whisper.csv\n",
        "- android_interview_depressed_whisper.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B7CPcmWEMErl"
      },
      "source": [
        "## ANDROID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_BJUnqR72Py"
      },
      "outputs": [],
      "source": [
        "android_reading_healthy_files = [os.path.join(android_reading_healthy_path, file) for file in os.listdir(android_reading_healthy_path)]\n",
        "\n",
        "android_reading_healthy_features_whisper = []\n",
        "\n",
        "for file in android_reading_healthy_files:\n",
        "    features = extract_features(file)\n",
        "    file_name = os.path.basename(file)\n",
        "    android_reading_healthy_features_whisper.append([file_name, 0] + list(features))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "luIV7BEu-kmL"
      },
      "outputs": [],
      "source": [
        "output_csv_path = \"android_reading_healthy_whisper.csv\"\n",
        "\n",
        "with open(output_csv_path, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    for row in android_reading_healthy_features_whisper:\n",
        "        writer.writerow(row)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytaym-W99C3D"
      },
      "outputs": [],
      "source": [
        "android_reading_depressed_files = [os.path.join(android_reading_depressed_path, file) for file in os.listdir(android_reading_depressed_path)]\n",
        "\n",
        "android_reading_depressed_features_whisper = []\n",
        "\n",
        "for file in android_reading_depressed_files:\n",
        "    features = extract_features(file)\n",
        "    file_name = os.path.basename(file)\n",
        "    android_reading_depressed_features_whisper.append([file_name, 1] + list(features))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdaEq77D-2bb"
      },
      "outputs": [],
      "source": [
        "output_csv_path = \"android_reading_depressed_whisper.csv\"\n",
        "\n",
        "with open(output_csv_path, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    for row in android_reading_depressed_features_whisper:\n",
        "        writer.writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8mYdXdIYki5"
      },
      "outputs": [],
      "source": [
        "android_interview_healthy_files = [os.path.join(android_interview_healthy_path, file) for file in os.listdir(android_interview_healthy_path)]\n",
        "\n",
        "android_interview_healthy_features_whisper = []\n",
        "\n",
        "for file in android_interview_healthy_files:\n",
        "    features = extract_features(file)\n",
        "    file_name = os.path.basename(file)\n",
        "    android_interview_healthy_features_whisper.append([file_name, 0] + list(features))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9Q1ShVH71bG"
      },
      "outputs": [],
      "source": [
        "output_csv_path = \"android_interview_healthy_whisper.csv\"\n",
        "\n",
        "with open(output_csv_path, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    for row in android_interview_healthy_features_whisper:\n",
        "        writer.writerow(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zq_1prP6ZHr6"
      },
      "outputs": [],
      "source": [
        "android_interview_depressed_files = [os.path.join(android_interview_depressed_path, file) for file in os.listdir(android_interview_depressed_path)]\n",
        "\n",
        "android_interview_depressed_features_whisper = []\n",
        "\n",
        "for file in android_interview_depressed_files:\n",
        "    features = extract_features(file)\n",
        "    file_name = os.path.basename(file)\n",
        "    android_interview_depressed_features_whisper.append([file_name, 1] + list(features))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wp1qTAxnAv-D"
      },
      "outputs": [],
      "source": [
        "output_csv_path = \"android_interview_depressed_whisper.csv\"\n",
        "\n",
        "with open(output_csv_path, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    for row in android_interview_depressed_features_whisper:\n",
        "        writer.writerow(row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I415hihVMIul"
      },
      "source": [
        "## EDAIC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "GQqBrwbkaTu-",
        "outputId": "69b4eab3-cfa4-461c-d494-8168da33355f"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-43a86b242dce>\u001b[0m in \u001b[0;36m<cell line: 15>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0medaic_test_features_whisper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features_with_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medaic_test_recordings_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medaic_test_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0medaic_validation_whisper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features_with_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medaic_validation_recordings_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medaic_validation_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-33-43a86b242dce>\u001b[0m in \u001b[0;36mextract_features_with_labels\u001b[0;34m(recordings_labels, base_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecordings_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfeatures_labels_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-317508305b83>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msample_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeature_extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/_backend/utils.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size, backend)\u001b[0m\n\u001b[1;32m    201\u001b[0m         \"\"\"\n\u001b[1;32m    202\u001b[0m         \u001b[0mbackend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffer_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/_backend/ffmpeg.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(uri, frame_offset, num_frames, normalize, channels_first, format, buffer_size)\u001b[0m\n\u001b[1;32m    332\u001b[0m             )\n\u001b[1;32m    333\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_audio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muri\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchaudio/_backend/ffmpeg.py\u001b[0m in \u001b[0;36mload_audio\u001b[0;34m(src, frame_offset, num_frames, convert, channels_first, format)\u001b[0m\n\u001b[1;32m     98\u001b[0m ) -> Tuple[torch.Tensor, int]:\n\u001b[1;32m     99\u001b[0m     \u001b[0mfilter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_load_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_frames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtorchaudio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchannels_first\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def extract_features_with_labels(recordings_labels, base_path):\n",
        "    features_labels_dataset = []\n",
        "    for file, label in recordings_labels:\n",
        "        file_path = os.path.join(base_path, file)\n",
        "        features = extract_features(file_path)\n",
        "\n",
        "        features_labels_dataset.append([file, label] + list(features))\n",
        "    return features_labels_dataset\n",
        "\n",
        "\n",
        "edaic_train_features_whisper = extract_features_with_labels(edaic_train_recordings_labels, edaic_train_path)\n",
        "\n",
        "edaic_test_features_whisper = extract_features_with_labels(edaic_test_recordings_labels, edaic_test_path)\n",
        "\n",
        "edaic_validation_whisper = extract_features_with_labels(edaic_validation_recordings_labels, edaic_validation_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9UL2MIkdqpb"
      },
      "outputs": [],
      "source": [
        "output_csv_path = \"edaic_train_features_whisper.csv\"\n",
        "\n",
        "with open(output_csv_path, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    for row in edaic_train_features_whisper:\n",
        "        writer.writerow(row)\n",
        "\n",
        "\n",
        "output_csv_path = \"edaic_test_features_whisper.csv\"\n",
        "\n",
        "with open(output_csv_path, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    for row in edaic_test_features_whisper:\n",
        "        writer.writerow(row)\n",
        "\n",
        "\n",
        "output_csv_path = \"edaic_validation_features_whisper.csv\"\n",
        "\n",
        "with open(output_csv_path, 'w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    for row in edaic_validation_whisper:\n",
        "        writer.writerow(row)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}